# Extract memory system into standalone service

## Summary

Extracts Bud's memory system (graph, activation, episodes, entities, traces, NER, entity extraction, pyramid summarization, retrieval) into a standalone library + HTTP service under `memory-service/`. This is **additive only** — no changes to existing Bud code.

## What was extracted

### Core packages (`memory-service/pkg/`)

| Package | Source | What it does |
|---------|--------|-------------|
| `graph/` | `internal/graph/` | Three-tier memory graph: episodes (Tier 1), entities (Tier 2), traces (Tier 3). SQLite storage, spreading activation, dual-trigger retrieval, pyramid compression, entity relations with temporal validity |
| `embedding/` | `internal/embedding/` | Ollama HTTP client for embedding generation (`nomic-embed-text`) and text generation/summarization (`llama3.2`) |
| `ner/` | `internal/ner/` | spaCy NER sidecar HTTP client for fast entity pre-filtering (~10ms per message) |
| `extract/` | `internal/extract/` | Two-tier entity extraction: fast regex (`FastExtractor`) + deep LLM (`DeepExtractor`). Entity resolution against existing graph. Relationship extraction. Temporal invalidation of contradicted facts |
| `filter/` | `internal/filter/` | Quality filtering: entropy scoring (entity novelty + semantic divergence) and dialogue act classification (backchannel detection) |
| `consolidate/` | `internal/consolidate/` | Episode grouping into traces via connected-component clustering on inferred edges, LLM summarization, similar-trace linking, reconsolidation |

### HTTP API (`memory-service/cmd/memory-service/`)

| Endpoint | Purpose |
|----------|---------|
| `POST /ingest` | Store episode → generate embedding → run NER pre-filter → deep LLM extraction → resolve entities against graph → generate pyramid summaries |
| `POST /recall` | Spreading activation retrieval: embed query → dual-trigger seed (semantic + lexical + entity) → 3-iteration activation spread → lateral inhibition → sigmoid → feeling-of-knowing gate → return ranked traces |
| `POST /context` | Assemble context window: fetch recent episodes → pyramid-compress (last 5 full, next 10 at L32, next 15 at L8) → optionally retrieve relevant memories for a query |
| `GET /health` | Service status, NER sidecar connectivity, graph statistics |

## Architectural decisions

### What was decoupled

**`ClaudeInference` → `InferenceClient` interface.** The original consolidation package imported `internal/executive` to run Claude sessions for episode edge inference. This was the only coupling point between the memory system and Bud's executive layer. I replaced it with a generic interface:

```go
type InferenceClient interface {
    Infer(ctx context.Context, prompt string) (string, error)
}
```

Any LLM (Claude, OpenAI, Ollama, etc.) can implement this. The prompts for edge inference and trace relationship detection are preserved exactly as they were.

**Summarization prompt made bot-agnostic.** The `embedding.Client.Summarize()` method had a Bud-specific prompt ("You are Bud, an AI assistant..."). Replaced with a generic memory trace summarization prompt that preserves the same output format.

### What stayed coupled (by design)

**`graph.DB` is the gravity center.** Nearly every package depends on `graph.DB` for storage — this mirrors the original architecture where the SQLite graph database is the single source of truth. Decoupling this further (e.g., storage interfaces) would add abstraction without benefit at this stage.

**`embedding.Client` serves dual duty.** It handles both embedding generation (`Embed()`) and text generation (`Generate()`, `Summarize()`). This matches Ollama's API structure where one server handles both. The `Compressor` interface in `graph/compression.go` already provides the abstraction point if you want to swap generation backends.

**Schema migrations are in `graph/db.go`.** The full migration chain (v1–v15) is preserved so the service can open existing Bud databases or create fresh ones. This is intentional — it means you can point the standalone service at Bud's existing `memory.db` for testing.

### Interface design rationale

**`extract.Generator`** — Minimal interface (`Generate(prompt string) (string, error)`) used by `DeepExtractor` and `Invalidator`. Keeps entity extraction independent of any specific LLM client.

**`extract.Embedder`** — Minimal interface (`Embed(text string) ([]float64, error)`) used by `Resolver` for entity resolution via embedding similarity.

**`graph.Compressor`** — Interface for pyramid summarization (`Generate(prompt string) (string, error)`). Lets you use any text generation backend for compression.

**`consolidate.LLMClient`** — Combined interface (`Embed`, `Summarize`, `Generate`) for the consolidation pipeline. Could be split further but matches the natural workflow.

**`consolidate.InferenceClient`** — The key new interface that replaces the Claude-specific `executive.RunCustomSession()` call. Single method, easy to implement.

## External dependencies

| Dependency | Required? | Why |
|-----------|-----------|-----|
| **Ollama** | Yes | Embedding generation and text generation are core to the memory system — embeddings for similarity search + spreading activation seeding, generation for pyramid compression + entity extraction + summarization |
| **spaCy NER sidecar** | Recommended, not required | Fast pre-filter (~10ms) to avoid expensive LLM extraction (~6s) on messages with no named entities. Falls back gracefully — if sidecar is down, all messages go through deep extraction |
| **SQLite** | Embedded (go-sqlite3) | The graph database. No external process needed |

## Trade-offs considered

**Copy vs. import.** I copied the source files rather than creating a Go workspace or using `replace` directives. Trade-off: code duplication, but the service has zero coupling to Bud's module and can evolve independently. This is appropriate for an extraction — once Dan is happy with the standalone version, the original packages could be refactored to import from here.

**Kept full schema migrations.** The standalone service carries all 15 schema migrations from Bud's history. Trade-off: slightly heavier initial code, but it means the service can open existing Bud databases directly for testing/migration, and new databases get the correct final schema.

**No consolidation endpoint.** The consolidation pipeline (`consolidate.Run()`) is available as a library but not exposed as an HTTP endpoint. Trade-off: consolidation involves long-running LLM calls (Claude for edge inference, Ollama for summarization) and is better suited to a background job or CLI command than a synchronous HTTP request. The `ingest` endpoint handles per-message entity extraction; consolidation should be run separately.

**Kept `prose` dependency.** The `extract/prose.go` file uses `github.com/tsawler/prose/v3` for NLP-based entity extraction. It's a medium-weight dependency (pulls in `gonum`). Trade-off: it provides a third extraction tier between fast regex and slow LLM, useful when spaCy sidecar is unavailable.

## What's NOT included (future work)

| Not included | Why | Future path |
|-------------|-----|-------------|
| **Conversation buffer** (`internal/buffer/`) | Tightly coupled to per-channel Discord semantics and session management. The `/context` endpoint provides the same pyramid-compressed output without the stateful buffer |  Could be added as a stateful middleware if needed |
| **Memory/percept pools** (`internal/memory/`) | Uses Bud's `internal/types.Percept` and `internal/types.Trace` which are v1 types superseded by the graph. The graph DB is the source of truth in v2 | Already obsolete in Bud's architecture |
| **Consolidation HTTP endpoint** | Long-running (minutes for large batches), involves Claude API calls, better as a background job | Add `POST /consolidate` with async job tracking, or a CLI subcommand |
| **Decay/maintenance endpoints** | Activation decay (`DecayActivationByAge`), trace pruning are operational concerns | Add `POST /maintenance/decay` or run as cron |
| **Authentication/authorization** | Service assumes trusted callers | Add API key or JWT middleware before production use |
| **Episode authorization checks** | Bud has `authorization_checked`/`has_authorization` fields for Discord permission gating | Application-specific; callers should gate before calling `/ingest` |
| **Test files** | The original test files reference Bud-specific test fixtures and internal packages | Should write new tests against the standalone API |

## Files changed

All additive — no modifications to existing Bud code (except `.gitignore` to exclude the binary).

```
memory-service/
├── README.md
├── go.mod
├── go.sum
├── cmd/memory-service/main.go          # HTTP server
└── pkg/
    ├── graph/
    │   ├── types.go                    # Episode, Entity, Trace, Edge types
    │   ├── db.go                       # SQLite DB + schema migrations
    │   ├── episodes.go                 # Episode CRUD + retrieval
    │   ├── entities.go                 # Entity CRUD + relations + resolution helpers
    │   ├── traces.go                   # Trace CRUD + activation + decay + linking
    │   ├── activation.go              # Spreading activation algorithm (Synapse-style)
    │   ├── compression.go             # Pyramid summarization (L4-L64)
    │   └── episode_trace_edges.go     # Episode↔episode and episode↔trace edges
    ├── embedding/ollama.go            # Ollama embedding + generation client
    ├── ner/client.go                  # spaCy NER sidecar client
    ├── extract/
    │   ├── fast.go                    # Regex-based fast extraction
    │   ├── deep.go                    # LLM-based deep extraction + relationships
    │   ├── prose.go                   # prose NLP library extraction
    │   ├── resolve.go                 # Entity resolution against graph
    │   └── invalidate.go             # Temporal fact invalidation
    ├── filter/
    │   ├── entropy.go                 # Entropy-based quality scoring
    │   └── dialogueact.go            # Dialogue act classification
    └── consolidate/
        ├── consolidate.go             # Episode grouping + trace creation
        └── inference.go               # Generic LLM inference interface (replaces ClaudeInference)
```
